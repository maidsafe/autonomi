name: PR Benchmarks

on: pull_request


env:
  CARGO_INCREMENTAL: '0'
  RUST_BACKTRACE: 1

jobs:
  benchmark:
    name: Compare benchmarks to main
    # right now only ubuntu, running on multiple systems would require many pushes...\
    # perhaps this can be done with one consolidation action in the future, pulling down all results and pushing
    # once to the branch..
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y heaptrack
      - uses: actions-rs/toolchain@v1
        id: toolchain
        with:
          profile: minimal
          toolchain: stable
          override: true
          components: rustfmt, clippy

      - uses: Swatinem/rust-cache@v1
        with:
          cache-on-failure: true

      - run: cargo install cargo-criterion

      - name: ubuntu install ripgrep
        run: sudo apt-get -y install ripgrep

     
      - name: Build sn bins
        run: cargo build --release --bins
        timeout-minutes: 30

      - name: Start a local network
        run: cargo run --release --bin testnet --features verify-nodes -- --interval 2000 --node-path ./target/release/safenode
        env:
          SN_LOG: "all"
        timeout-minutes: 10

      - name: Set contact env var node.
        shell: bash
        # get all nodes listen ports
        run: echo "SAFE_PEERS=$(rg "listening on \".+\"" ~/.safe -u | rg '/ip4.*$' -m1 -o | rg '"' -r '')" >> "$GITHUB_ENV"

      - name: Check contact peer
        shell: bash
        run: echo "Peer is $SAFE_PEERS"

      # Start a heaptracked node instance to compare memory usage
      - name: Start safenode with heaptrack
        run: |
          mkdir -p ~/.safe/heapnode
          heaptrack ./target/release/safenode --root-dir ~/.safe/heapnode --log-dir ~/.safe/heapnode &
          sleep 10
        env:
          SN_LOG: "all"

      ########################
      ### Benchmark itself ###
      ########################

      - name: Bench `safe`
        shell: bash
        # Criterion outputs the actual bench results to stderr "2>&1 tee output.txt" takes stderr,
        # passes to tee which displays it in the terminal and writes to output.txt
        run: | 
          cargo criterion --message-format=json 2>&1 | tee -a output.txt
          cat output.txt | rg benchmark-complete | jq -c '{
              name: (.id | split("/")[-1]),
              unit: "MiB/s",
              value: ((.throughput[0].per_iteration / (1024*1024)) / (.mean.estimate / 1e9))
          }' > files-benchmark.json


      - name: Check for Client heaptrack file
        shell: bash
        run: | 
          ls -la  
          cat files-benchmark.json        
     
      #################################
      ### Log any regression alerts ###
      #################################
      # Run `github-action-benchmark` action
      - name: Store benchmark result
        uses: benchmark-action/github-action-benchmark@v1
        with:
          # What benchmark tool the output.txt came from
          tool: 'customBiggerIsBetter'
          output-file-path: files-benchmark.json
          # Where the previous data file is stored
          external-data-json-path: ./cache/benchmark-data.json
          # Workflow will fail when an alert happens
          fail-on-alert: true
          # GitHub API token to make a commit comment
          github-token: ${{ secrets.GITHUB_TOKEN }}
          # Enable alert commit comment
          comment-on-alert: true
          # 200% regression will result in alert
          alert-threshold: '200%'
          # Enable Job Summary for PRs
          summary-always: true


      # Start a heaptracked client instance to compare memory usage
      # The generated large single file (around 450MB) may vary little bit along the releases
      - name: Start client with heaptrack
        shell: bash
        run: |
          tar -czvf release_zip.tar.gz ./target/release
          heaptrack ./target/release/safe files upload -- "./release_zip.tar.gz"
        env:
          SN_LOG: "all"


      ### CLEANUP ###
      - name: Kill all nodes
        shell: bash
        timeout-minutes: 1
        if: failure()
        continue-on-error: true
        run: |
          pkill safenode
          echo "$(pgrep safenode | wc -l) nodes still running"

      - name: Tar log files
        shell: bash
        continue-on-error: true
        run: |
          find ~/.safe/heapnode -iname '*.log*' | tar -zcvf heap_node_log_files.tar.gz --files-from -
          find ~/.safe/node/local-test-network -iname '*.log*' | tar -zcvf nodes_log_files.tar.gz --files-from -
          find /tmp/safe-client -iname '*.log*' | tar -zcvf client_log_files.tar.gz --files-from -
          find . -iname '*log_files.tar.gz' | tar -zcvf log_files.tar.gz --files-from -
        if: failure()

      - name: Upload Logs
        uses: actions/upload-artifact@main
        with:
          name: sn_node_logs_benchmark_prs
          path: log_files.tar.gz
        if: failure()
        continue-on-error: true
      
      #########################
      ### Node Mem Analysis ###
      #########################
      - name: Check for Node heaptrack file
        run: ls -la
        shell: bash


      - name: Analyze node memory usage
        shell: bash
        run: |
          HEAPTRACK_FILE=$(ls -t heaptrack.safenode.*.zst | head -1)
          heaptrack --analyze $HEAPTRACK_FILE > heaptrack.safenode.txt
        if: always()

      - name: Upload Node Heaptrack
        uses: actions/upload-artifact@main
        with:
          name: heaptrack_safenode
          path: heaptrack.safenode.*
        continue-on-error: true
        if: always()

      # The large file uploaded will increase node's peak mem usage a lot
      - name: Check node memory usage
        id: node-memory-usage-check
        shell: bash
        env:
          NODE_MEM_LIMIT_MB: "100" # mb
        run: |
          MEMORY_USAGE=$(rg "peak heap memory consumption" ./heaptrack.safenode.txt | awk '{print $5}' | rg "M" -r "")
          echo "Memory usage: $MEMORY_USAGE MB"
          if (( $(echo "$MEMORY_USAGE > $NODE_MEM_LIMIT_MB" | bc -l) )); then
            echo "Node memory usage exceeded threshold: $MEMORY_USAGE MB"
            exit 1
          fi
          # Write the node memory usage to a file
          echo '[
              {
                  "name": "node-memory-usage-through-safe-benchmark",
                  "value": '$MEMORY_USAGE',
                  "unit": "MB"
              }
          ]' > node_memory_usage.json
        if: always()

      - name: Alert for node memory usage
        uses: benchmark-action/github-action-benchmark@v1
        with:
          tool: 'customSmallerIsBetter'
          output-file-path: node_memory_usage.json
          # Where the previous data file is stored
          external-data-json-path: ./cache/node-mem-usage.json
          # Workflow will fail when an alert happens
          fail-on-alert: true
          # GitHub API token to make a commit comment
          github-token: ${{ secrets.GITHUB_TOKEN }}
          # Enable alert commit comment
          comment-on-alert: true
          # Comment on the PR
          comment-always: true
          # 200% regression will result in alert
          alert-threshold: '200%'
          # Enable Job Summary for PRs
          summary-always: true

      ###########################
      ### Client Mem Analysis ###
      ###########################
      - name: Check for Client heaptrack file
        run: ls -la
        shell: bash


      - name: Analyze client memory usage
        shell: bash
        run: |
          HEAPTRACK_FILE=$(ls -t heaptrack.safe.*.zst | head -1)
          heaptrack --analyze $HEAPTRACK_FILE > heaptrack.safe.txt
        if: always()

      - name: Upload Client Heaptrack
        uses: actions/upload-artifact@main
        with:
          name: heaptrack_safe
          path: heaptrack.safe.*
        continue-on-error: true
        if: always()

      - name: Check client memory usage
        id: client-memory-usage-check
        shell: bash
        env:
          CLIENT_MEM_LIMIT_MB: "1000" # mb
        run: |
          MEMORY_USAGE=$(rg "peak heap memory consumption" ./heaptrack.safe.txt | awk '{print $5}' | rg "M" -r "")
          echo "Memory usage: $MEMORY_USAGE MB"
          if (( $(echo "$MEMORY_USAGE > $CLIENT_MEM_LIMIT_MB" | bc -l) )); then
            echo "Client memory usage exceeded threshold: $MEMORY_USAGE MB"
            exit 1
          fi
          # Write the client memory usage to a file
          echo '[
              {
                  "name": "client-memory-usage-through-safe-benchmark",
                  "value": '$MEMORY_USAGE',
                  "unit": "MB"
              }
          ]' > client_memory_usage.json
        if: always()

      - name: Alert for client memory usage
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: 'Memory Usage of Client during uploading large file'
          tool: 'customSmallerIsBetter'
          output-file-path: client_memory_usage.json
          # Where the previous data file is stored
          external-data-json-path: ./cache/client-mem-usage.json
          # Workflow will fail when an alert happens
          fail-on-alert: true
          # GitHub API token to make a commit comment
          github-token: ${{ secrets.GITHUB_TOKEN }}
          # Enable alert commit comment
          comment-on-alert: true
          # 200% regression will result in alert
          alert-threshold: '200%'
          # Enable Job Summary for PRs
          summary-always: true
